Operating System: Linux 4.18.0-425.13.1.el8_7.x86_64
System Type: 64bit
CPU Model: AMD EPYC 7343 16-Core Processor
Number of Cores: 32
Number of Threads: 64
Memory (GB): 251.74080657958984
Number of cores being actually used/requested for the benchmark: 2
Confirming that the environment variables are properly set...
OMP_NUM_THREADS = 2
OPENBLAS_NUM_THREADS = 2
MKL_NUM_THREADS = 2
VECLIB_MAXIMUM_THREADS = 2
NUMEXPR_NUM_THREADS = 2
PYSCF_MAX_MEMORY = 225000
#INFO: **** input file is /home/lu29vow/GPU_Test/tmp_dir/PyFock/benchmarks_tests/bench_PySCF_vs_PyFock_GPU.py ****
####### NOTE: The scipy.linalg library appears to be using double the number of threads supplied for some reason.
####### To avoid such issues messing up the benchmarks, the benchmark should be run as 'taskset --cpu-list 0-3 python3 benchmark_DFT_LDA_DF.py'
####### This way one can set the number of CPUs seen by the python process and the benchmark would be much more reliable.
####### Furthermore, to confirm the CPU and memory usage throughout the whole process, one can profilie it using  
####### psrecord 13447 --interval 1 --duration 120 --plot 13447.png
#######
####### This may be required in some cases when using GPU on WSL
####### export NUMBA_CUDA_DRIVER="/usr/lib/wsl/lib/libcuda.so.1"

import os
import platform
import psutil
import numba
numba.config.THREADING_LAYER='omp'
# Set the number of threads/cores to be used by PyFock and PySCF
ncores = 2
os.environ['OMP_NUM_THREADS'] = str(ncores)
os.environ["OPENBLAS_NUM_THREADS"] = str(ncores) # export OPENBLAS_NUM_THREADS=4 
os.environ["MKL_NUM_THREADS"] = str(ncores) # export MKL_NUM_THREADS=4
os.environ["VECLIB_MAXIMUM_THREADS"] = str(ncores) # export VECLIB_MAXIMUM_THREADS=4
# os.environ["NUMEXPR_NUM_THREADS"] = str(ncores) # export NUMEXPR_NUM_THREADS=4
os.environ["NUMEXPR_NUM_THREADS"] = str(ncores) # export NUMEXPR_NUM_THREADS=1
# Set the max memory for PySCF
os.environ["PYSCF_MAX_MEMORY"] = str(225000) 

# Print system information 
from pyfock import Utils

Utils.print_sys_info()

# Check if the environment variables are properly set
print("Number of cores being actually used/requested for the benchmark:", ncores)
print('Confirming that the environment variables are properly set...')
print('OMP_NUM_THREADS =', os.environ.get('OMP_NUM_THREADS', None))
print('OPENBLAS_NUM_THREADS =', os.environ.get('OPENBLAS_NUM_THREADS', None))
print('MKL_NUM_THREADS =', os.environ.get('MKL_NUM_THREADS', None))
print('VECLIB_MAXIMUM_THREADS =', os.environ.get('VECLIB_MAXIMUM_THREADS', None))
print('NUMEXPR_NUM_THREADS =', os.environ.get('NUMEXPR_NUM_THREADS', None))
print('PYSCF_MAX_MEMORY =', os.environ.get('PYSCF_MAX_MEMORY', None))


# Run your tasks here
from pyfock import Basis
from pyfock import Mol
from pyfock import Integrals
from pyfock import DFT
from timeit import default_timer as timer
import numpy as np
import scipy

from pyscf import gto, dft, df, scf
from gpu4pyscf import dft as dft_gpu

#DFT SCF benchmark and comparison with PySCF
#Benchmarking and performance assessment and comparison using various techniques and different softwares

# LDA_X LDA_C_VWN 
funcx = 1
funcc = 7

# LDA_X LDA_C_PW 
# funcx = 1
# funcc = 12

# LDA_X LDA_C_PW_MOD 
# funcx = 1
# funcc = 13

# GGA_X_PBE, GGA_C_PBE (PBE)
# funcx = 101
# funcc = 130

# GGA_X_B88, GGA_C_LYP (BLYP)
# funcx = 106
# funcc = 131

funcidcrysx = [funcx, funcc]
funcidpyscf = str(funcx)+','+str(funcc)

# basis_set_name = 'sto-2g'
# basis_set_name = 'sto-3g'
# basis_set_name = 'sto-6g'
# basis_set_name = '6-31G'
basis_set_name = 'def2-SVP'
# basis_set_name = 'def2-SVPD'
# basis_set_name = 'def2-TZVP'
# basis_set_name = 'def2-QZVP'
# basis_set_name = 'def2-TZVPP'
# basis_set_name = 'def2-QZVPP'
# basis_set_name = 'def2-TZVPD'
# basis_set_name = 'def2-QZVPD'
# basis_set_name = 'def2-TZVPPD'
# basis_set_name = 'def2-QZVPPD'
# basis_set_name = 'cc-pVDZ'
# basis_set_name = 'ano-rcc'

auxbasis_name = 'def2-universal-jfit'
# auxbasis_name = 'def2-universal-jkfit'
# auxbasis_name = 'def2-TZVP'
# auxbasis_name = 'sto-3g'
# auxbasis_name = 'def2-SVP'
# auxbasis_name = '6-31G'

# xyzFilename = 'Benzene-Fulvene_Dimer.xyz'
# xyzFilename = 'Adenine-Thymine.xyz'
# xyzFilename = 'Zn.xyz'
# xyzFilename = 'Zn_dimer.xyz'
# xyzFilename = 'TPP.xyz'
# xyzFilename = 'Zn_TPP.xyz'
# xyzFilename = 'H2O.xyz'

# xyzFilename = 'Caffeine.xyz'
# xyzFilename = 'Serotonin.xyz'
# xyzFilename = 'Cholesterol.xyz'
# xyzFilename = 'C60.xyz'
# xyzFilename = 'Taxol.xyz'
# xyzFilename = 'Valinomycin.xyz'
# xyzFilename = 'Olestra.xyz'
# xyzFilename = 'Ubiquitin.xyz'

### 1D Carbon Alkanes
# xyzFilename = 'Ethane.xyz'
xyzFilename = 'Decane_C10H22.xyz'
# xyzFilename = 'Icosane_C20H42.xyz'
# xyzFilename = 'Tetracontane_C40H82.xyz'
# xyzFilename = 'Pentacontane_C50H102.xyz'
# xyzFilename = 'Octacontane_C80H162.xyz'
# xyzFilename = 'Hectane_C100H202.xyz'
# xyzFilename = 'Icosahectane_C120H242.xyz'

### 2D Carbon
# xyzFilename = 'Graphene_C16.xyz'
# xyzFilename = 'Graphene_C76.xyz'
# xyzFilename = 'Graphene_C102.xyz'
# xyzFilename = 'Graphene_C184.xyz'
# xyzFilename = 'Graphene_C210.xyz'
# xyzFilename = 'Graphene_C294.xyz'

### 3d Carbon Fullerenes
# xyzFilename = 'C60.xyz'
# xyzFilename = 'C70.xyz'
# xyzFilename = 'Graphene_C102.xyz'
# xyzFilename = 'Graphene_C184.xyz'
# xyzFilename = 'Graphene_C210.xyz'
# xyzFilename = 'Graphene_C294.xyz'


# ---------PySCF---------------
#Comparison with PySCF
molPySCF = gto.Mole()
molPySCF.atom = xyzFilename
molPySCF.basis = basis_set_name
molPySCF.cart = False
molPySCF.verbose = 4
molPySCF.max_memory=25000
# molPySCF.incore_anyway = True # Keeps the PySCF ERI integrals incore
molPySCF.build()
#print(molPySCF.cart_labels())

print('\n\nPySCF Results\n\n')
start=timer()
mf = dft_gpu.rks.RKS(molPySCF).density_fit(auxbasis=auxbasis_name)
# mf = scf.RHF(molPySCF).density_fit(auxbasis=auxbasis_name)
mf.xc = funcidpyscf
mf.verbose = 6
# dmat_init = mf.init_guess_by_1e(molPySCF)
# dmat_init = mf.init_guess_by_huckel(molPySCF)
mf.init_guess = 'minao'
dmat_init = mf.init_guess_by_minao(molPySCF)
# mf.init_guess = 'atom'
# dmat_init = mf.init_guess_by_atom(molPySCF)
mf.max_cycle = 30
mf.conv_tol = 1e-7
mf.grids.level = 5
energyPyscf = mf.kernel(dm0=dmat_init)
print('Nuc-Nuc PySCF= ', molPySCF.energy_nuc())
print('One electron integrals energy',mf.scf_summary['e1'])
print('Coulomb energy ',mf.scf_summary['coul'])
print('EXC ',mf.scf_summary['exc'])
duration = timer()-start
print('PySCF time: ', duration)
pyscfGrids = mf.grids
print('PySCF Grid Size: ', pyscfGrids.weights.shape)
mf = 0#None

# Get an initial guess for dmat from PySCF using CAO basis (Need to use CPU pyscf for this as GPU version oesnt support SAO yet)
molPySCF.cart = True
molPySCF.build()
mf2 = dft_gpu.rks.RKS(molPySCF).density_fit(auxbasis=auxbasis_name)
mf2.init_guess = 'minao'
dmat_init = mf2.init_guess_by_minao(molPySCF)
import cupy as cp
cp._default_memory_pool.free_all_blocks()

import psutil

# Get memory information
memory_info = psutil.virtual_memory()

# Convert bytes to human-readable format
used_memory = psutil._common.bytes2human(memory_info.used)


# If you want to print in a more human-readable format, you can use psutil's utility function
print(f"Currently Used memory: {used_memory}")
#--------------------CrysX --------------------------

#Initialize a Mol object with somewhat large geometry
molCrysX = Mol(coordfile=xyzFilename)
print('\n\nNatoms :',molCrysX.natoms)
# print(molCrysX.coordsBohrs)

#Initialize a Basis object with a very large basis set
basis = Basis(molCrysX, {'all':Basis.load(mol=molCrysX, basis_name=basis_set_name)})
print('\n\nNAO :',basis.bfs_nao)

auxbasis = Basis(molCrysX, {'all':Basis.load(mol=molCrysX, basis_name=auxbasis_name)})
print('\n\naux NAO :',auxbasis.bfs_nao)

dftObj = DFT(molCrysX, basis, xc=funcidcrysx)
# GPU acceleration
dftObj.use_gpu = True
dftObj.keep_ao_in_gpu = False
dftObj.use_libxc = False
dftObj.n_streams = 1 # Changing this to anything other than 1 won't make any difference 
dftObj.n_gpus = 1 # Specify the number of GPUs
dftObj.free_gpu_mem = True
dftObj.threads_x = 32
dftObj.threads_y = 32
dftObj.dynamic_precision = False
dftObj.keep_ints3c2e_in_gpu = True
# SAO or CAO basis
dftObj.sao = False
# print(dmat_init)
# Using PySCF grids to compare the energies
energyCrysX, dmat = dftObj.scf(max_itr=35, ncores=ncores, dmat=dmat_init, conv_crit=1.0E-7, grids=pyscfGrids, \
                               isDF=True, auxbasis=auxbasis, rys=True, DF_algo=10, blocksize=20480, XC_algo=3, debug=False, \
                                sortGrids=False, save_ao_values=False, xc_bf_screen=True, threshold_schwarz=1e-9, \
                                strict_schwarz=False, cholesky=True, orthogonalize=True)
# print(dmat)

# Using CrysX grids 
# To get the same energies as PySCF (level=5) upto 1e-7 au, use the following settings
# radial_precision=1.0e-13
# level=3
# pruning by density with threshold = 1e-011
# alpha_min and alpha_max corresponding to QZVP
# energyCrysX, dmat = dftObj.scf(max_itr=30, ncores=ncores, dmat=dmat_init, grids=None, gridsLevel=3, isDF=True, auxbasis=auxbasis,
#                             rys=True, DF_algo=6, blocksize=5000, XC_algo=2, debug=False, sortGrids=False, save_ao_values=True,
#                             xc_bf_screen=True,threshold_schwarz=1e-9)


print('Energy diff (PySCF-CrysX)', abs(energyCrysX-energyPyscf[0]))

#Print package versions
import joblib
import scipy
import numba
import threadpoolctl
import opt_einsum
import pylibxc
import llvmlite 
import cupy
import numexpr
import pyscf
print('\n\n\n Package versions')
print('pyscf version', pyscf.__version__)
# print('psi4 version', psi4.__version__)
print('np version', np.__version__)
print('joblib version', joblib.__version__)
print('numba version', numba.__version__)
print('threadpoolctl version', threadpoolctl.__version__)
print('opt_einsum version', opt_einsum.__version__)
# print('pylibxc version', pylibxc.__version__)
print('llvmlite version', llvmlite.__version__)
print('cupy version', cupy.__version__)
print('numexpr version', numexpr.__version__)
print('scipy version', scipy.__version__)

#INFO: ******************** input file end ********************


System: uname_result(system='Linux', node='gpu011.cluster', release='4.18.0-425.13.1.el8_7.x86_64', version='#1 SMP Tue Feb 21 04:20:52 EST 2023', machine='x86_64')  Threads 2
Python 3.10.13 (tags/v3.10.13-25-g07fbd8e9251-dirty:07fbd8e9251, Sep 27 2023, 23:32:09) [GCC 13.2.0]
numpy 1.26.3  scipy 1.10.1
Date: Sat Feb  3 23:40:56 2024
PySCF version 2.4.0
PySCF path  /home/lu29vow/.conda/envs/GPU2/lib/python3.10/site-packages/pyscf

[ENV] PYSCF_MAX_MEMORY 225000
[CONFIG] conf_file None
[INPUT] verbose = 4
[INPUT] num. atoms = 32
[INPUT] num. electrons = 82
[INPUT] charge = 0
[INPUT] spin (= nelec alpha-beta = 2S) = 0
[INPUT] symmetry False subgroup None
[INPUT] Mole.unit = angstrom
[INPUT] Symbol           X                Y                Z      unit          X                Y                Z       unit  Magmom
[INPUT]  1 C      0.660900000000   0.387900000000   0.066100000000 AA    1.248919995725   0.733024763719   0.124910896834 Bohr   0.0
[INPUT]  2 C     -0.642900000000  -0.416100000000   0.097200000000 AA   -1.214904925483  -0.786315040432   0.183681379308 Bohr   0.0
[INPUT]  3 C      1.914100000000  -0.489400000000   0.024000000000 AA    3.617124775030  -0.924831965362   0.045353426990 Bohr   0.0
[INPUT]  4 C     -1.896200000000   0.462500000000   0.063500000000 AA   -3.583298677400   0.873998332611   0.119997608910 Bohr   0.0
[INPUT]  5 C      3.185800000000   0.361800000000   0.007100000000 AA    6.020289487639   0.683702911868   0.013417055484 Bohr   0.0
[INPUT]  6 C     -3.199200000000  -0.343000000000   0.034200000000 AA   -6.045611817709  -0.648176060726   0.064628633460 Bohr   0.0
[INPUT]  7 C      4.438100000000  -0.511000000000  -0.073500000000 AA    8.386793513432  -0.965650049653  -0.138894870156 Bohr   0.0
[INPUT]  8 C     -4.449800000000   0.530500000000  -0.074800000000 AA   -8.408903309090   1.002499709082  -0.141351514117 Bohr   0.0
[INPUT]  9 C      5.705000000000   0.329500000000  -0.056800000000 AA   10.780887540644   0.622664758044  -0.107336443875 Bohr   0.0
[INPUT] 10 C     -5.715800000000  -0.312900000000  -0.087000000000 AA  -10.801296582789  -0.591295304376  -0.164406172837 Bohr   0.0
[INPUT] 11 H      0.654500000000   1.046100000000  -0.811600000000 AA    1.236825748528   1.976842498908  -1.533701722697 Bohr   0.0
[INPUT] 12 H      0.700300000000   1.037900000000   0.949000000000 AA    1.323375205033   1.961346744686   1.793350092212 Bohr   0.0
[INPUT] 13 H     -0.661800000000  -1.040700000000   0.998600000000 AA   -1.250620749237  -1.966637977835   1.887080507991 Bohr   0.0
[INPUT] 14 H     -0.661600000000  -1.098500000000  -0.761600000000 AA   -1.250242804012  -2.075864147835  -1.439215416469 Bohr   0.0
[INPUT] 15 H      1.926200000000  -1.154000000000   0.896400000000 AA    3.639990461137  -2.180743947748   1.693950498060 Bohr   0.0
[INPUT] 16 H      1.883700000000  -1.126300000000  -0.868200000000 AA    3.559677100843  -2.128398534098  -1.640660221347 Bohr   0.0
[INPUT] 17 H     -1.899000000000   1.124300000000   0.938300000000 AA   -3.588589910549   2.124619081848   1.773130022679 Bohr   0.0
[INPUT] 18 H     -1.856400000000   1.108400000000  -0.822400000000 AA   -3.508087577643   2.094572436468  -1.554110764842 Bohr   0.0
[INPUT] 19 H      3.160900000000   1.045500000000  -0.850300000000 AA    5.973235307138   1.975708663233  -1.606834123718 Bohr   0.0
[INPUT] 20 H      3.224700000000   0.980000000000   0.912300000000 AA    6.093799833885   1.851931602074   1.723997143441 Bohr   0.0
[INPUT] 21 H     -3.172100000000  -1.037400000000  -0.814900000000 AA   -5.994400239733  -1.960401881624  -1.539937818908 Bohr   0.0
[INPUT] 22 H     -3.260200000000  -0.955900000000   0.942100000000 AA   -6.160885111307  -1.806389202472   1.780310981953 Bohr   0.0
[INPUT] 23 H      4.460200000000  -1.209400000000   0.771100000000 AA    8.428556460785  -2.285434775049   1.457167814652 Bohr   0.0
[INPUT] 24 H      4.415400000000  -1.111100000000  -0.990500000000 AA    8.343896730405  -2.099674697004  -1.871773726382 Bohr   0.0
[INPUT] 25 H     -4.488700000000   1.228900000000   0.769100000000 AA   -8.482413655335   2.322284434478   1.453388362403 Bohr   0.0
[INPUT] 26 H     -4.405200000000   1.129900000000  -0.991300000000 AA   -8.324621523934   2.135201548146  -1.873285507281 Bohr   0.0
[INPUT] 27 H      6.587900000000  -0.314500000000  -0.116200000000 AA   12.449326736022  -0.594318866176  -0.219586175674 Bohr   0.0
[INPUT] 28 H      5.774200000000   0.916700000000   0.864500000000 AA   10.911656588464   1.732311938389   1.633668234686 Bohr   0.0
[INPUT] 29 H      5.729400000000   1.019000000000  -0.906700000000 AA   10.826996858083   1.925630920932  -1.713414677143 Bohr   0.0
[INPUT] 30 H     -6.598200000000   0.329900000000  -0.165500000000 AA  -12.468790915105   0.623420648494  -0.312749673616 Bohr   0.0
[INPUT] 31 H     -5.720200000000  -1.001500000000  -0.937900000000 AA  -10.809611377737  -1.892560713752  -1.772374132230 Bohr   0.0
[INPUT] 32 H     -5.804400000000  -0.900800000000   0.832000000000 AA  -10.968726317425  -1.702265293008   1.572252135638 Bohr   0.0

nuclear repulsion = 519.13846685665
number of shells = 126
number of NR pGTOs = 394
number of NR cGTOs = 250
basis = def2-SVP
ecp = {}
CPU time:         2.98


PySCF Results


Initial guess from minao.


******** <class 'gpu4pyscf.df.df_jk.DFRKS'> ********
method = DFRKS
initial guess = minao
damping factor = 0
level_shift factor = 0
DIIS = <class 'gpu4pyscf.scf.diis.CDIIS'>
diis_start_cycle = 1
diis_space = 8
SCF conv_tol = 1e-07
SCF conv_tol_grad = None
SCF max_cycles = 30
direct_scf = False
chkfile to save SCF result = /tmp/tmphs421byg
max_memory 25000 MB (current use 1818 MB)
XC library pyscf.dft.libxc version 6.1.0
    unable to decode the reference due to https://github.com/NVIDIA/cuda-python/issues/29
XC functionals = 1,7
    P. A. M. Dirac.,  Math. Proc. Cambridge Philos. Soc. 26, 376 (1930)
    F. Bloch.,  Z. Phys. 57, 545 (1929)
    S. H. Vosko, L. Wilk, and M. Nusair.,  Can. J. Phys. 58, 1200 (1980)
radial grids: 
    Treutler-Ahlrichs [JCP 102, 346 (1995); DOI:10.1063/1.469408] (M4) radial grids
    
becke partition: Becke, JCP 88, 2547 (1988); DOI:10.1063/1.454033
pruning grids: <function nwchem_prune at 0x149e4b775750>
grids dens level: 5
symmetrized grids: False
atomic radii adjust function: <function treutler_atomic_radii_adjust at 0x149e4b7755a0>
small_rho_cutoff = 1e-07
Set gradient conv threshold to 0.000316228
tot grids = 949120
prune_by_density_: 39 padding grids
    CPU time for                                   setting up grids      0.84 sec, wall time      0.85 sec, GPU time for    852.09 ms
    CPU time for                                            vxc tot      0.09 sec, wall time      0.09 sec, GPU time for     90.28 ms
    CPU time for                                           jk total      0.00 sec, wall time      0.01 sec, GPU time for      5.86 ms
E1 = -1549.8552728358036  Ecoul = 698.492456676146  Exc = -58.12443736565727
init E= -390.348786668665
    CPU time for                                         total prep      1.35 sec, wall time      1.25 sec, GPU time for   1247.71 ms
    CPU time for                                               DIIS      0.00 sec, wall time      0.00 sec, GPU time for      0.01 ms
    CPU time for                                                eig      0.00 sec, wall time      0.00 sec, GPU time for      3.88 ms
    CPU time for                                                 dm      0.00 sec, wall time      0.00 sec, GPU time for      3.26 ms
    CPU time for                                            vxc tot      0.03 sec, wall time      0.03 sec, GPU time for     32.32 ms
    CPU time for                                           jk total      0.00 sec, wall time      0.00 sec, GPU time for      1.79 ms
    CPU time for                                               veff      0.03 sec, wall time      0.03 sec, GPU time for     34.17 ms
E1 = -1567.0427138071254  Ecoul = 717.2401097553276  Exc = -59.411500766227064
    CPU time for                                             energy      0.00 sec, wall time      0.00 sec, GPU time for      0.58 ms
    CPU time for                                              total      0.04 sec, wall time      0.05 sec, GPU time for     46.51 ms
cycle= 1 E= -390.075637961375  delta_E= 0.273  |ddm|= 5.48
diis-norm(errvec)=1.96995
diis-c [-3.88071459  1.        ]
    CPU time for                                               DIIS      0.01 sec, wall time      0.01 sec, GPU time for     14.17 ms
    CPU time for                                                eig      0.00 sec, wall time      0.00 sec, GPU time for      3.89 ms
    CPU time for                                                 dm      0.00 sec, wall time      0.00 sec, GPU time for      0.78 ms
    CPU time for                                            vxc tot      0.03 sec, wall time      0.03 sec, GPU time for     32.00 ms
    CPU time for                                           jk total      0.00 sec, wall time      0.00 sec, GPU time for      1.78 ms
    CPU time for                                               veff      0.03 sec, wall time      0.03 sec, GPU time for     33.84 ms
E1 = -1541.6714343599792  Ecoul = 690.106855549197  Exc = -57.36975204549568
    CPU time for                                             energy      0.00 sec, wall time      0.00 sec, GPU time for      0.58 ms
    CPU time for                                              total      0.05 sec, wall time      0.05 sec, GPU time for     53.37 ms
cycle= 2 E= -389.795863999628  delta_E= 0.28  |ddm|= 2.65
diis-norm(errvec)=3.02988
diis-c [-0.04275172  0.60676131  0.39323869]
    CPU time for                                               DIIS      0.00 sec, wall time      0.00 sec, GPU time for      1.12 ms
    CPU time for                                                eig      0.00 sec, wall time      0.00 sec, GPU time for      3.88 ms
    CPU time for                                                 dm      0.00 sec, wall time      0.00 sec, GPU time for      0.77 ms
    CPU time for                                            vxc tot      0.03 sec, wall time      0.03 sec, GPU time for     32.68 ms
    CPU time for                                           jk total      0.00 sec, wall time      0.00 sec, GPU time for      1.75 ms
    CPU time for                                               veff      0.03 sec, wall time      0.03 sec, GPU time for     34.50 ms
E1 = -1557.6135301126465  Ecoul = 706.7485288289727  Exc = -58.55925942442437
    CPU time for                                             energy      0.00 sec, wall time      0.00 sec, GPU time for      0.57 ms
    CPU time for                                              total      0.04 sec, wall time      0.04 sec, GPU time for     40.95 ms
cycle= 3 E= -390.285793851448  delta_E= -0.49  |ddm|= 1.71
diis-norm(errvec)=0.122156
diis-c [-0.00219026  0.19649023  0.13826233  0.66524745]
    CPU time for                                               DIIS      0.00 sec, wall time      0.00 sec, GPU time for      1.25 ms
    CPU time for                                                eig      0.00 sec, wall time      0.00 sec, GPU time for      3.87 ms
    CPU time for                                                 dm      0.00 sec, wall time      0.00 sec, GPU time for      0.75 ms
    CPU time for                                            vxc tot      0.03 sec, wall time      0.03 sec, GPU time for     32.16 ms
    CPU time for                                           jk total      0.00 sec, wall time      0.00 sec, GPU time for      1.75 ms
    CPU time for                                               veff      0.03 sec, wall time      0.03 sec, GPU time for     33.97 ms
E1 = -1557.3638355897751  Ecoul = 706.4928513103355  Exc = -58.55381507639806
    CPU time for                                             energy      0.00 sec, wall time      0.00 sec, GPU time for      0.57 ms
    CPU time for                                              total      0.04 sec, wall time      0.04 sec, GPU time for     40.52 ms
cycle= 4 E= -390.286332499188  delta_E= -0.000539  |ddm|= 0.094
diis-norm(errvec)=0.0466078
diis-c [-3.27600632e-04  7.44830563e-02  5.55437010e-02  3.42461758e-01
  5.27511484e-01]
    CPU time for                                               DIIS      0.00 sec, wall time      0.00 sec, GPU time for      1.39 ms
    CPU time for                                                eig      0.00 sec, wall time      0.00 sec, GPU time for      3.88 ms
    CPU time for                                                 dm      0.00 sec, wall time      0.00 sec, GPU time for      0.76 ms
    CPU time for                                            vxc tot      0.03 sec, wall time      0.03 sec, GPU time for     32.23 ms
    CPU time for                                           jk total      0.00 sec, wall time      0.00 sec, GPU time for      1.76 ms
    CPU time for                                               veff      0.03 sec, wall time      0.03 sec, GPU time for     34.04 ms
E1 = -1557.3491923423985  Ecoul = 706.4762912612861  Exc = -58.551998828119345
    CPU time for                                             energy      0.00 sec, wall time      0.00 sec, GPU time for      0.56 ms
    CPU time for                                              total      0.04 sec, wall time      0.04 sec, GPU time for     40.73 ms
cycle= 5 E= -390.286433052582  delta_E= -0.000101  |ddm|= 0.0289
diis-norm(errvec)=0.0161478
diis-c [-1.15482999e-05  7.97543125e-03  7.97307933e-03  6.75854176e-02
  2.80152267e-01  6.36313804e-01]
    CPU time for                                               DIIS      0.00 sec, wall time      0.00 sec, GPU time for      1.52 ms
    CPU time for                                                eig      0.00 sec, wall time      0.00 sec, GPU time for      3.86 ms
    CPU time for                                                 dm      0.00 sec, wall time      0.00 sec, GPU time for      0.75 ms
    CPU time for                                            vxc tot      0.03 sec, wall time      0.03 sec, GPU time for     32.43 ms
    CPU time for                                           jk total      0.00 sec, wall time      0.00 sec, GPU time for      1.75 ms
    CPU time for                                               veff      0.03 sec, wall time      0.03 sec, GPU time for     34.24 ms
E1 = -1557.3326707693066  Ecoul = 706.458336116391  Exc = -58.55057880643507
    CPU time for                                             energy      0.00 sec, wall time      0.00 sec, GPU time for      0.56 ms
    CPU time for                                              total      0.04 sec, wall time      0.04 sec, GPU time for     41.04 ms
cycle= 6 E= -390.2864466027  delta_E= -1.36e-05  |ddm|= 0.00971
diis-norm(errvec)=0.00292407
diis-c [-1.13432706e-06  1.63977300e-03  2.24640300e-03  2.06918683e-02
  1.11415890e-01  2.94693691e-01  5.69312375e-01]
    CPU time for                                               DIIS      0.00 sec, wall time      0.00 sec, GPU time for      1.64 ms
    CPU time for                                                eig      0.00 sec, wall time      0.00 sec, GPU time for      3.87 ms
    CPU time for                                                 dm      0.00 sec, wall time      0.00 sec, GPU time for      0.75 ms
    CPU time for                                            vxc tot      0.03 sec, wall time      0.03 sec, GPU time for     32.00 ms
    CPU time for                                           jk total      0.00 sec, wall time      0.00 sec, GPU time for      1.73 ms
    CPU time for                                               veff      0.03 sec, wall time      0.03 sec, GPU time for     33.80 ms
E1 = -1557.3283782866188  Ecoul = 706.4537826316418  Exc = -58.550318193081274
    CPU time for                                             energy      0.00 sec, wall time      0.00 sec, GPU time for      0.56 ms
    CPU time for                                              total      0.04 sec, wall time      0.04 sec, GPU time for     40.74 ms
cycle= 7 E= -390.286446991408  delta_E= -3.89e-07  |ddm|= 0.00207
diis-norm(errvec)=0.00106291
diis-c [-1.00558393e-07  1.69642073e-04  4.93118096e-04  4.38415209e-03
  3.05253571e-02  9.25534334e-02  3.09201558e-01  5.62672739e-01]
    CPU time for                                               DIIS      0.00 sec, wall time      0.00 sec, GPU time for      1.80 ms
    CPU time for                                                eig      0.00 sec, wall time      0.00 sec, GPU time for      3.87 ms
    CPU time for                                                 dm      0.00 sec, wall time      0.00 sec, GPU time for      0.76 ms
    CPU time for                                            vxc tot      0.03 sec, wall time      0.03 sec, GPU time for     31.98 ms
    CPU time for                                           jk total      0.00 sec, wall time      0.00 sec, GPU time for      1.77 ms
    CPU time for                                               veff      0.03 sec, wall time      0.03 sec, GPU time for     33.81 ms
E1 = -1557.3281684241238  Ecoul = 706.4535103035718  Exc = -58.55025578673302
    CPU time for                                             energy      0.00 sec, wall time      0.00 sec, GPU time for      0.57 ms
    CPU time for                                              total      0.04 sec, wall time      0.04 sec, GPU time for     40.92 ms
cycle= 8 E= -390.286447050635  delta_E= -5.92e-08  |ddm|= 0.00059
    CPU time for                                                SCF      1.71 sec, wall time      1.62 sec, GPU time for   1616.90 ms
converged SCF energy = -390.286447050635
Nuc-Nuc PySCF=  519.1384668566502
One electron integrals energy -1557.3281684241238
Coulomb energy  706.4535103035718
EXC  -58.55025578673302
PySCF time:  1.6979837194085121
PySCF Grid Size:  (773760,)
Initial guess from minao.
Currently Used memory: 4.4G


Natoms : 32


NAO : 260


aux NAO : 874
Running DFT using 2 threads for Numba.


GPU acceleration is enabled. Currently this only accelerates AO values and XC term evaluation.
GPU(s) information:
Found 1 CUDA devices
id 0    b'NVIDIA A100 80GB PCIe'                              [SUPPORTED]
                      Compute Capability: 8.0
                           PCI Device ID: 0
                              PCI Bus ID: 129
                                    UUID: GPU-532978f3-f5cc-04fc-9dc8-613a4acb4a20
                                Watchdog: Disabled
             FP32/FP64 Performance Ratio: 2
Summary:
	1/1 devices are supported
True
Max threads per block supported by the GPU:  1024
The user has specified to use 1 GPU(s).
Threads per block configuration for the XC term:  (32, 32)
Threads per block configuration for the all other calculations:  (32, 32)

Calculating one electron integrals...


Core H size in GB  0.0005408
done!
Time taken 0.08472608402371407 seconds.


Calculating three centered two electron and two-centered two-electron integrals...


Time taken for two-centered two-electron integrals 0.04462835192680359 seconds.



Performing Schwarz screening...
Threshold  1e-09
Time taken to evaluate the "diagonal" of 4c2e ERI tensor:  0.02004166692495346
Time taken to evaluate the square roots needed:  0.00017457455396652222
Time for significant indices evaluation:  0.1978833768516779
Size of permanent array storing the significant indices of 3c2e ERI in GB  0.000814328
No. of elements in the standard three-centered two electron ERI tensor:  59082400
No. of elements in the triangular three-centered two electron ERI tensor:  29654820
No. of significant triplets based on Schwarz inequality and triangularity: 18773740 or 31.8% of original
Schwarz screening done!
Total time taken for Schwarz screening 0.21821456961333752 seconds.

Two Center Two electron ERI size in GB  0.006111008
Three Center Two electron ERI size in GB  0.15018992
Three-centered two electron evaluation done!
Time taken for Cholesky factorization fo two-centered two-electron integrals 0.007782559841871262 seconds.

Time taken for Coulomb term related calculations (integrals, screening, prelims..) with the density fitting approximation  1.1780844181776047 seconds.


Using the user supplied grids!



No. of supplied/generated grid points:  773760
Size (in GB) for storing the coordinates of grid:       0.01857024
Size (in GB) for storing the weights of grid:           0.00619008
Size (in GB) for storing the density at gridpoints:     0.00619008

Will use batching to evaluate the XC term for memory efficiency.
Batch size:  20480
No. of batches:  38

Preliminary processing for XC term evaluations...
Calculating the value of basis functions (atomic orbitals) and get the indices of siginificantly contributing functions...
done!
Time taken 0.022864526137709618 seconds.

Maximum no. of basis functions contributing to a batch of grid points:    187
Average no. of basis functions contributing to a batch of grid points:    144


------------------------------------------------------
Exchange-Correlation Functional
------------------------------------------------------

XC Functional IDs supplied:  [1, 7]


Description of exchange functional: 

The Exchange function belongs to the family: LDA
Functional ID: 1
Functional Name: lda_x
Attributes:
    Name: Slater exchange
    Kind: 0
  Family: 1
Citations:
   P. A. M. Dirac.,  Math. Proc. Cambridge Philos. Soc. 26, 376 (1930)
   F. Bloch.,  Z. Phys. 57, 545 (1929)


Description of correlation functional: 

 The Correlation function belongs to the family: LDA
Functional ID: 7
Functional Name: lda_c_vwn
Attributes:
    Name: Vosko, Wilk & Nusair (VWN5)
    Kind: 1
  Family: 1
Citations:
   S. H. Vosko, L. Wilk, and M. Nusair.,  Can. J. Phys. 58, 1200 (1980)
------------------------------------------------------




Calculating XC term using GPU and algo 3
Not using LibXC for XC evaluations
Number of electrons:  81.83533645236768



------Iteration 1--------


Energies
Electron-Nuclear Energy       -1941.8346120297115
Nuclear repulsion Energy      519.1384668580413
Kinetic Energy                394.2871173386256
Coulomb Energy                696.281936684772
Exchange-Correlation Energy   -58.05407871822301
-------------------------
Total Energy  -390.1811698664957
-------------------------



Energy difference :  390.1811698664957


Time taken for the previous iteration: 0.19310327246785164


Calculating XC term using GPU and algo 3
Not using LibXC for XC evaluations
Number of electrons:  82.00000082487186



------Iteration 2--------


Energies
Electron-Nuclear Energy       -1955.9299113800537
Nuclear repulsion Energy      519.1384668580413
Kinetic Energy                388.21421056015674
Coulomb Energy                717.8074003511274
Exchange-Correlation Energy   -59.292132391226325
-------------------------
Total Energy  -390.0619660019545
-------------------------



Energy difference :  0.11920386454119125


Time taken for the previous iteration: 0.13008661195635796


Calculating XC term using GPU and algo 3
Not using LibXC for XC evaluations
Number of electrons:  82.00000106945939



------Iteration 3--------


Energies
Electron-Nuclear Energy       -1917.7113609591954
Nuclear repulsion Energy      519.1384668580413
Kinetic Energy                376.97888980056723
Coulomb Energy                688.9862098720445
Exchange-Correlation Energy   -57.17183144697762
-------------------------
Total Energy  -389.7796258755201
-------------------------



Energy difference :  0.28234012643440565


Time taken for the previous iteration: 0.12873709201812744


Calculating XC term using GPU and algo 3
Not using LibXC for XC evaluations
Number of electrons:  82.00000089244182



------Iteration 4--------


Energies
Electron-Nuclear Energy       -1941.727961128393
Nuclear repulsion Energy      519.1384668580413
Kinetic Energy                384.2525569207081
Coulomb Energy                706.4410643260856
Exchange-Correlation Energy   -58.41704835553853
-------------------------
Total Energy  -390.31292137909645
-------------------------



Energy difference :  0.5332955035763689


Time taken for the previous iteration: 0.12838790193200111


Calculating XC term using GPU and algo 3
Not using LibXC for XC evaluations
Number of electrons:  82.00000090242062



------Iteration 5--------


Energies
Electron-Nuclear Energy       -1941.315045135966
Nuclear repulsion Energy      519.1384668580413
Kinetic Energy                384.1513264877828
Coulomb Energy                706.1166402238681
Exchange-Correlation Energy   -58.404879134090535
-------------------------
Total Energy  -390.31349070036447
-------------------------



Energy difference :  0.00056932126801712


Time taken for the previous iteration: 0.12731288373470306


Calculating XC term using GPU and algo 3
Not using LibXC for XC evaluations
Number of electrons:  82.00000089899731



------Iteration 6--------


Energies
Electron-Nuclear Energy       -1941.2742346347434
Nuclear repulsion Energy      519.1384668580413
Kinetic Energy                384.12883826702506
Coulomb Energy                706.0952251329262
Exchange-Correlation Energy   -58.401922732037164
-------------------------
Total Energy  -390.31362710878795
-------------------------



Energy difference :  0.0001364084234865004


Time taken for the previous iteration: 0.12835798040032387


Calculating XC term using GPU and algo 3
Not using LibXC for XC evaluations
Number of electrons:  82.00000090103327



------Iteration 7--------


Energies
Electron-Nuclear Energy       -1941.2488548983106
Nuclear repulsion Energy      519.1384668580413
Kinetic Energy                384.11731259625805
Coulomb Energy                706.0797154889054
Exchange-Correlation Energy   -58.40027964451752
-------------------------
Total Energy  -390.31363959962334
-------------------------



Energy difference :  1.24908353882347e-05


Time taken for the previous iteration: 0.12879640236496925


Calculating XC term using GPU and algo 3
Not using LibXC for XC evaluations
Number of electrons:  82.00000090021932



------Iteration 8--------


Energies
Electron-Nuclear Energy       -1941.2446003582995
Nuclear repulsion Energy      519.1384668580413
Kinetic Energy                384.1162912761839
Coulomb Energy                706.0763041297485
Exchange-Correlation Energy   -58.40010192491097
-------------------------
Total Energy  -390.3136400192368
-------------------------



Energy difference :  4.196134568701382e-07


Time taken for the previous iteration: 0.1282848473638296


Calculating XC term using GPU and algo 3
Not using LibXC for XC evaluations
Number of electrons:  82.00000090025584



------Iteration 9--------


Energies
Electron-Nuclear Energy       -1941.244703312955
Nuclear repulsion Energy      519.1384668580413
Kinetic Energy                384.116232625926
Coulomb Energy                706.0764406811036
Exchange-Correlation Energy   -58.40007692387648
-------------------------
Total Energy  -390.3136400717606
-------------------------



Energy difference :  5.252377377473749e-08


Time taken for the previous iteration: 0.1282880362123251



SCF Converged after 9 iterations!

-------------------------------------
Total Energy =  -390.3136400717606
-------------------------------------



Time taken : 2.521506618708372 seconds.



-------------------------------------
Profiling
-------------------------------------
Preprocessing                           0.022864526137709618
Density Fitting                         0.1425261814147234
    DF (gamma)                          0.05665482580661774
    DF (coeff)                          0.038651030510663986
    DF (Jtri)                           0.02447877824306488
    DF (Cholesky)                       0.007782559841871262
DIIS                                    0.02516334503889084
KS matrix diagonalization               0.08349014446139336
One electron Integrals (S, T, Vnuc)     0.08472608402371407
Coulomb Integrals (2c2e + 3c2e)         1.1703018583357334
Grids construction                      0
Exchange-Correlation Term               0.9665031265467405
Misc.                                   0.025931352749466896
Complete SCF                            2.521506618708372
