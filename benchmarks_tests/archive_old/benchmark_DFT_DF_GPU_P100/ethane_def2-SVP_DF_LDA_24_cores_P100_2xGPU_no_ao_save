Operating System: Linux 3.10.0-957.1.3.el7.x86_64
System Type: 64bit
CPU Model: Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz
Number of Cores: 24
Number of Threads: 48
Memory (GB): 125.80519104003906
Number of cores being actually used/requested for the benchmark: 24
Confirming that the environment variables are properly set...
OMP_NUM_THREADS = 24
OPENBLAS_NUM_THREADS = 24
MKL_NUM_THREADS = 24
VECLIB_MAXIMUM_THREADS = 24
NUMEXPR_NUM_THREADS = 24
PYSCF_MAX_MEMORY = 125000
#INFO: **** input file is /home/lu29vow/GPU_Test/benchmark/PyFock/benchmarks_tests/benchmark_DFT_LDA_DF.py ****
####### NOTE: The scipy.linalg library appears to be using double the number of threads supplied for some reason.
####### To avoid such issues messing up the benchmarks, the benchmark should be run as 'taskset --cpu-list 0-3 python3 benchmark_DFT_LDA_DF.py'
####### This way one can set the number of CPUs seen by the python process and the benchmark would be much more reliable.
####### Furthermore, to confirm the CPU and memory usage throughout the whole process, one can profilie it using  
####### psrecord 13447 --interval 1 --duration 120 --plot 13447.png
#######
####### This may be required in some cases when using GPU on WSL
####### export NUMBA_CUDA_DRIVER="/usr/lib/wsl/lib/libcuda.so.1"

import os
import platform
import psutil
# import numba
# numba.config.THREADING_LAYER='omp'
# Set the number of threads/cores to be used by PyFock and PySCF
ncores = 24
os.environ['OMP_NUM_THREADS'] = str(ncores)
os.environ["OPENBLAS_NUM_THREADS"] = str(ncores) # export OPENBLAS_NUM_THREADS=4 
os.environ["MKL_NUM_THREADS"] = str(ncores) # export MKL_NUM_THREADS=4
os.environ["VECLIB_MAXIMUM_THREADS"] = str(ncores) # export VECLIB_MAXIMUM_THREADS=4
# os.environ["NUMEXPR_NUM_THREADS"] = str(ncores) # export NUMEXPR_NUM_THREADS=4
os.environ["NUMEXPR_NUM_THREADS"] = str(ncores) # export NUMEXPR_NUM_THREADS=1
# Set the max memory for PySCF
os.environ["PYSCF_MAX_MEMORY"] = str(125000) 

# Print system information 
from pyfock import Utils

Utils.print_sys_info()

# Check if the environment variables are properly set
print("Number of cores being actually used/requested for the benchmark:", ncores)
print('Confirming that the environment variables are properly set...')
print('OMP_NUM_THREADS =', os.environ.get('OMP_NUM_THREADS', None))
print('OPENBLAS_NUM_THREADS =', os.environ.get('OPENBLAS_NUM_THREADS', None))
print('MKL_NUM_THREADS =', os.environ.get('MKL_NUM_THREADS', None))
print('VECLIB_MAXIMUM_THREADS =', os.environ.get('VECLIB_MAXIMUM_THREADS', None))
print('NUMEXPR_NUM_THREADS =', os.environ.get('NUMEXPR_NUM_THREADS', None))
print('PYSCF_MAX_MEMORY =', os.environ.get('PYSCF_MAX_MEMORY', None))


# Run your tasks here
from pyfock import Basis
from pyfock import Mol
from pyfock import Integrals
from pyfock import DFT
from timeit import default_timer as timer
import numpy as np
import scipy

from pyscf import gto, dft, df

#DFT SCF benchmark and comparison with PySCF
#Benchmarking and performance assessment and comparison using various techniques and different softwares

# LDA_X LDA_C_VWN 
funcx = 1
funcc = 7

# LDA_X LDA_C_PW 
# funcx = 1
# funcc = 12

# LDA_X LDA_C_PW_MOD 
# funcx = 1
# funcc = 13

# GGA_X_PBE, GGA_C_PBE (PBE)
# funcx = 101
# funcc = 130

# GGA_X_B88, GGA_C_LYP (BLYP)
# funcx = 106
# funcc = 131

funcidcrysx = [funcx, funcc]
funcidpyscf = str(funcx)+','+str(funcc)

# basis_set_name = 'sto-2g'
# basis_set_name = 'sto-3g'
# basis_set_name = 'sto-6g'
# basis_set_name = '6-31G'
basis_set_name = 'def2-SVP'
# basis_set_name = 'def2-SVPD'
# basis_set_name = 'def2-TZVP'
# basis_set_name = 'def2-QZVP'
# basis_set_name = 'def2-TZVPP'
# basis_set_name = 'def2-QZVPP'
# basis_set_name = 'def2-TZVPD'
# basis_set_name = 'def2-QZVPD'
# basis_set_name = 'def2-TZVPPD'
# basis_set_name = 'def2-QZVPPD'
# basis_set_name = 'cc-pVDZ'
# basis_set_name = 'ano-rcc'

auxbasis_name = 'def2-universal-jfit'
# auxbasis_name = 'def2-TZVP'
# auxbasis_name = 'sto-3g'
# auxbasis_name = 'def2-SVP'
# auxbasis_name = '6-31G'

# xyzFilename = 'Benzene-Fulvene_Dimer.xyz'
# xyzFilename = 'Adenine-Thymine.xyz'
# xyzFilename = 'Zn.xyz'
# xyzFilename = 'Zn_dimer.xyz'
# xyzFilename = 'TPP.xyz'
# xyzFilename = 'Zn_TPP.xyz'
# xyzFilename = 'H2O.xyz'

# xyzFilename = 'Caffeine.xyz'
# xyzFilename = 'Serotonin.xyz'
# xyzFilename = 'Cholesterol.xyz'
# xyzFilename = 'C60.xyz'
# xyzFilename = 'Taxol.xyz'
# xyzFilename = 'Valinomycin.xyz'
# xyzFilename = 'Olestra.xyz'
# xyzFilename = 'Ubiquitin.xyz'

### 1D Carbon Alkanes
xyzFilename = 'Ethane.xyz'
# xyzFilename = 'Decane_C10H22.xyz'
# xyzFilename = 'Icosane_C20H42.xyz'
# xyzFilename = 'Tetracontane_C40H82.xyz'
# xyzFilename = 'Pentacontane_C50H102.xyz'
# xyzFilename = 'Octacontane_C80H162.xyz'
# xyzFilename = 'Hectane_C100H202.xyz'
# xyzFilename = 'Icosahectane_C120H242.xyz'

### 2D Carbon
# xyzFilename = 'Graphene_C16.xyz'
# xyzFilename = 'Graphene_C76.xyz'
# xyzFilename = 'Graphene_C102.xyz'
# xyzFilename = 'Graphene_C184.xyz'
# xyzFilename = 'Graphene_C210.xyz'
# xyzFilename = 'Graphene_C294.xyz'

### 3d Carbon Fullerenes
# xyzFilename = 'C60.xyz'
# xyzFilename = 'C70.xyz'
# xyzFilename = 'C76.xyz'
# xyzFilename = 'C78a.xyz'
# xyzFilename = 'C84a.xyz'
# xyzFilename = 'C90.xyz'


# ---------PySCF---------------
#Comparison with PySCF
molPySCF = gto.Mole()
molPySCF.atom = xyzFilename
molPySCF.basis = basis_set_name
molPySCF.cart = True
molPySCF.verbose = 4
molPySCF.max_memory=25000
# molPySCF.incore_anyway = True # Keeps the PySCF ERI integrals incore
molPySCF.build()
#print(molPySCF.cart_labels())

print('\n\nPySCF Results\n\n')
start=timer()
mf = dft.rks.RKS(molPySCF).density_fit(auxbasis=auxbasis_name)
mf.xc = funcidpyscf
# mf.verbose = 4
mf.direct_scf = False
# mf.with_df.max_memory = 25000
# dmat_init = mf.init_guess_by_1e(molPySCF)
# dmat_init = mf.init_guess_by_huckel(molPySCF)
mf.init_guess = 'minao'
dmat_init = mf.init_guess_by_minao(molPySCF)
# mf.init_guess = 'atom'
# dmat_init = mf.init_guess_by_atom(molPySCF)
mf.max_cycle = 30
mf.conv_tol = 1e-7
mf.grids.level = 5
print('begin df build')
start_df_pyscf=timer()
# mf.with_df.build()
duration_df_pyscf = timer()- start_df_pyscf
print('PySCF df time: ', duration_df_pyscf)
print('end df build')
energyPyscf = mf.kernel(dm0=dmat_init)
print('Nuc-Nuc PySCF= ', molPySCF.energy_nuc())
print('One electron integrals energy',mf.scf_summary['e1'])
print('Coulomb energy ',mf.scf_summary['coul'])
print('EXC ',mf.scf_summary['exc'])
duration = timer()-start
print('PySCF time: ', duration)
pyscfGrids = mf.grids
print('PySCF Grid Size: ', pyscfGrids.weights.shape)
print('\n\n PySCF Dipole moment')
dmat = mf.make_rdm1()
mol_dip_pyscf = mf.dip_moment(molPySCF, dmat, unit='AU')
mf = 0#None
import psutil

# Get memory information
memory_info = psutil.virtual_memory()

# Convert bytes to human-readable format
used_memory = psutil._common.bytes2human(memory_info.used)


# If you want to print in a more human-readable format, you can use psutil's utility function
print(f"Currently Used memory: {used_memory}")
#--------------------CrysX --------------------------

#Initialize a Mol object with somewhat large geometry
molCrysX = Mol(coordfile=xyzFilename)
print('\n\nNatoms :',molCrysX.natoms)
# print(molCrysX.coordsBohrs)

#Initialize a Basis object with a very large basis set
basis = Basis(molCrysX, {'all':Basis.load(mol=molCrysX, basis_name=basis_set_name)})
print('\n\nNAO :',basis.bfs_nao)

auxbasis = Basis(molCrysX, {'all':Basis.load(mol=molCrysX, basis_name=auxbasis_name)})
print('\n\naux NAO :',auxbasis.bfs_nao)

dftObj = DFT(molCrysX, basis, xc=funcidcrysx)
# GPU acceleration
dftObj.use_gpu = True
dftObj.keep_ao_in_gpu = False
dftObj.use_libxc = False
dftObj.n_streams = 1 # Changing this to anything other than 1 won't make any difference 
dftObj.n_gpus = 2 # Specify the number of GPUs
dftObj.free_gpu_mem = True
dftObj.threads_x = 16
dftObj.threads_y = 16
# SAO or CAO basis
dftObj.sao = False
# print(dmat_init)
# Using PySCF grids to compare the energies
energyCrysX, dmat = dftObj.scf(max_itr=35, ncores=ncores, dmat=dmat_init, conv_crit=1.0E-7, grids=pyscfGrids, \
                               isDF=True, auxbasis=auxbasis, rys=True, DF_algo=6, blocksize=51200, XC_algo=3, debug=False, \
                                sortGrids=False, save_ao_values=False, xc_bf_screen=True, threshold_schwarz=1e-9, \
                                strict_schwarz=True, cholesky=True, orthogonalize=True)
# print(dmat)

# Using CrysX grids 
# To get the same energies as PySCF (level=5) upto 1e-7 au, use the following settings
# radial_precision=1.0e-13
# level=3
# pruning by density with threshold = 1e-011
# alpha_min and alpha_max corresponding to QZVP
# energyCrysX, dmat = dftObj.scf(max_itr=30, ncores=ncores, dmat=dmat_init, grids=None, gridsLevel=3, isDF=True, auxbasis=auxbasis,
#                             rys=True, DF_algo=6, blocksize=5000, XC_algo=2, debug=False, sortGrids=False, save_ao_values=True,
#                             xc_bf_screen=True,threshold_schwarz=1e-9)


print('Energy diff (PySCF-CrysX)', abs(energyCrysX-energyPyscf))

print('\n\nPyFock Dipole moment')
M = Integrals.dipole_moment_mat_symm(basis)
mol_dip = molCrysX.get_dipole_moment(M, dmat)
print('Dipole moment(X, Y, Z, A.U.):', *mol_dip)
print('Max Diff dipole moment (PySCF-CrysX)', abs(mol_dip_pyscf-mol_dip).max())

#Print package versions
import joblib
import scipy
import numba
import threadpoolctl
import opt_einsum
import pylibxc
import llvmlite 
import cupy
import numexpr
import pyscf
print('\n\n\n Package versions')
print('pyscf version', pyscf.__version__)
# print('psi4 version', psi4.__version__)
print('np version', np.__version__)
print('joblib version', joblib.__version__)
print('numba version', numba.__version__)
print('threadpoolctl version', threadpoolctl.__version__)
print('opt_einsum version', opt_einsum.__version__)
# print('pylibxc version', pylibxc.__version__)
print('llvmlite version', llvmlite.__version__)
print('cupy version', cupy.__version__)
print('numexpr version', numexpr.__version__)
print('scipy version', scipy.__version__)
#INFO: ******************** input file end ********************


System: uname_result(system='Linux', node='node128', release='3.10.0-957.1.3.el7.x86_64', version='#1 SMP Thu Nov 29 14:49:43 UTC 2018', machine='x86_64', processor='x86_64')  Threads 24
Python 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) 
[GCC 10.3.0]
numpy 1.22.3  scipy 1.10.1
Date: Mon Jan  8 12:34:36 2024
PySCF version 2.4.0
PySCF path  /home/lu29vow/.local/lib/python3.8/site-packages/pyscf

[ENV] PYSCF_MAX_MEMORY 125000
[CONFIG] conf_file None
[INPUT] verbose = 4
[INPUT] num. atoms = 8
[INPUT] num. electrons = 18
[INPUT] charge = 0
[INPUT] spin (= nelec alpha-beta = 2S) = 0
[INPUT] symmetry False subgroup None
[INPUT] Mole.unit = angstrom
[INPUT] Cartesian GTO integrals (6d 10f)
[INPUT] Symbol           X                Y                Z      unit          X                Y                Z       unit  Magmom
[INPUT]  1 C     -0.759130000000   0.027045000000   0.000000000000 AA   -1.434547792941   0.051107643039   0.000000000000 Bohr   0.0
[INPUT]  2 C      0.759130000000  -0.027045000000   0.000000000000 AA    1.434547792941  -0.051107643039   0.000000000000 Bohr   0.0
[INPUT]  3 H     -1.125990000000   0.306235000000   1.010150000000 AA   -2.127812718999   0.578700279756   1.908906844729 Bohr   0.0
[INPUT]  4 H     -1.171340000000  -0.966695000000  -0.274750000000 AA   -2.213511798748  -1.826788795986  -0.519202252724 Bohr   0.0
[INPUT]  5 H     -1.109050000000   0.781825000000  -0.735390000000 AA   -2.095800758449   1.477435127338  -1.389685694744 Bohr   0.0
[INPUT]  6 H      1.109040000000  -0.781815000000   0.735390000000 AA    2.095781861188  -1.477416230077   1.389685694744 Bohr   0.0
[INPUT]  7 H      1.171340000000   0.966695000000   0.274760000000 AA    2.213511798748   1.826788795986   0.519221149985 Bohr   0.0
[INPUT]  8 H      1.125990000000  -0.306235000000  -1.010150000000 AA    2.127812718999  -0.578700279756  -1.908906844729 Bohr   0.0

nuclear repulsion = 42.0362430684635
number of shells = 30
number of NR pGTOs = 92
number of NR cGTOs = 60
basis = def2-SVP
ecp = {}
CPU time:         4.52


PySCF Results


Initial guess from minao.
begin df build
PySCF df time:  1.2289965525269508e-06
end df build


******** <class 'pyscf.df.df_jk.DFRKS'> ********
method = DFRKS
initial guess = minao
damping factor = 0
level_shift factor = 0
DIIS = <class 'pyscf.scf.diis.CDIIS'>
diis_start_cycle = 1
diis_space = 8
SCF conv_tol = 1e-07
SCF conv_tol_grad = None
SCF max_cycles = 30
direct_scf = False
chkfile to save SCF result = /tmp/tmpl6nff_69
max_memory 25000 MB (current use 341 MB)
XC library pyscf.dft.libxc version 6.1.0
    S. Lehtola, C. Steigemann, M. J.T. Oliveira, and M. A.L. Marques.,  SoftwareX 7, 1â€“5 (2018)
XC functionals = 1,7
    P. A. M. Dirac.,  Math. Proc. Cambridge Philos. Soc. 26, 376 (1930)
    F. Bloch.,  Z. Phys. 57, 545 (1929)
    S. H. Vosko, L. Wilk, and M. Nusair.,  Can. J. Phys. 58, 1200 (1980)
radial grids: 
    Treutler-Ahlrichs [JCP 102, 346 (1995); DOI:10.1063/1.469408] (M4) radial grids
    
becke partition: Becke, JCP 88, 2547 (1988); DOI:10.1063/1.454033
pruning grids: <function nwchem_prune at 0x2b1d146de940>
grids dens level: 5
symmetrized grids: False
atomic radii adjust function: <function treutler_atomic_radii_adjust at 0x2b1d146de8b0>
small_rho_cutoff = 1e-07
Set gradient conv threshold to 0.000316228
tot grids = 227848
init E= -78.7668720775058
  HOMO = -0.37720604309269  LUMO = 4.13349664806946e-05
cycle= 1 E= -78.9264083830177  delta_E= -0.16  |g|= 0.444  |ddm|= 2.52
  HOMO = -0.20832178516935  LUMO = 0.0747327284444437
cycle= 2 E= -78.8404554405631  delta_E= 0.086  |g|= 0.718  |ddm|=  1.1
  HOMO = -0.290124314905369  LUMO = 0.0402804208215401
cycle= 3 E= -78.9835982833725  delta_E= -0.143  |g|= 0.0181  |ddm|= 0.687
  HOMO = -0.292214809942134  LUMO = 0.0385552642463742
cycle= 4 E= -78.9836657740803  delta_E= -6.75e-05  |g|= 0.00653  |ddm|= 0.0254
  HOMO = -0.292160017376113  LUMO = 0.0385502981730364
cycle= 5 E= -78.9836765002109  delta_E= -1.07e-05  |g|= 0.000231  |ddm|= 0.00668
  HOMO = -0.292206894883038  LUMO = 0.0384986235709423
cycle= 6 E= -78.9836765138449  delta_E= -1.36e-08  |g|= 1.87e-05  |ddm|= 0.000227
  HOMO = -0.292218287523073  LUMO = 0.0384923746581832
Extra cycle  E= -78.9836765137516  delta_E= 9.33e-11  |g|= 2.81e-05  |ddm|= 4.7e-05
converged SCF energy = -78.9836765137516
Nuc-Nuc PySCF=  42.0362430684635
One electron integrals energy -188.7668838182488
Coulomb energy  79.92912337058786
EXC  -12.182159134554198
PySCF time:  5.201246751938015
PySCF Grid Size:  (193480,)


 PySCF Dipole moment
Dipole moment(X, Y, Z, A.U.):  0.00000, -0.00000,  0.00000
Currently Used memory: 1.7G


Natoms : 8


NAO : 60


aux NAO : 194
Running DFT using 24 threads for Numba.


GPU acceleration is enabled. Currently this only accelerates AO values and XC term evaluation.
GPU(s) information:
Found 2 CUDA devices
id 0    b'Tesla P100-PCIE-16GB'                              [SUPPORTED]
                      Compute Capability: 6.0
                           PCI Device ID: 0
                              PCI Bus ID: 130
                                    UUID: GPU-cefbe660-bed5-ab84-503f-8a8987cb7a4a
                                Watchdog: Disabled
             FP32/FP64 Performance Ratio: 2
id 1    b'Tesla P100-PCIE-16GB'                              [SUPPORTED]
                      Compute Capability: 6.0
                           PCI Device ID: 0
                              PCI Bus ID: 131
                                    UUID: GPU-4143789e-e476-1de0-7c0a-85e5014181db
                                Watchdog: Disabled
             FP32/FP64 Performance Ratio: 2
Summary:
	2/2 devices are supported
True
Max threads per block supported by the GPU:  1024
The user has specified to use 2 GPU(s).
Threads per block configuration:  (16, 16)


Will use dynamic precision. 
This means that the XC term will be evaluated in single precision until the 
relative energy difference b/w successive iterations is less than 5.0E-7.

Calculating overlap and kinetic integrals...


Core H size in GB  5.76e-05
done!
Time taken 0.40925498004071414 seconds.


Calculating three centered two electron and two-centered two-electron integrals...


Time taken for two-centered two-electron integrals 0.04478419607039541 seconds.



Performing Schwarz screening...
Threshold  1e-09
Time taken to evaluate the "diagonal" of 4c2e ERI tensor:  0.023051243973895907
Time taken to evaluate the square roots needed:  5.301903001964092e-05
Time for significant indices evaluation:  0.008877857006154954
Size of permanent array storing the significant indices of 3c2e ERI in GB  0.002128644
No. of elements in the standard three-centered two electron ERI tensor:  698400
No. of elements in the triangular three-centered two electron ERI tensor:  355020
No. of significant triplets based on Schwarz inequality and triangularity: 354774 or 50.8% of original
Schwarz screening done!
Total time taken for Schwarz screening 0.03211519494652748 seconds.

Time taken to evaluate the nuclear potential matrix with strict Schwarz screening:  0.20819033205043525
Two Center Two electron ERI size in GB  0.000301088
Three Center Two electron ERI size in GB  0.002838192
Three-centered two electron evaluation done!
Time taken for Cholesky factorization fo two-centered two-electron integrals 0.003401919035241008 seconds.

Time taken for Coulomb term related calculations (integrals, screening, prelims..) with the density fitting approximation  1.2092157839797437 seconds.


Using the user supplied grids!



No. of supplied/generated grid points:  193480
Size (in GB) for storing the coordinates of grid:       0.00464352
Size (in GB) for storing the weights of grid:           0.00154784
Size (in GB) for storing the density at gridpoints:     0.00154784

Will use batching to evaluate the XC term for memory efficiency.
Batch size:  51200
No. of batches:  4

Preliminary processing for XC term evaluations...
Calculating the value of basis functions (atomic orbitals) and get the indices of siginificantly contributing functions...
done!
Time taken 0.015878101927228272 seconds.

Maximum no. of basis functions contributing to a batch of grid points:    60
Average no. of basis functions contributing to a batch of grid points:    59


------------------------------------------------------
Exchange-Correlation Functional
------------------------------------------------------

XC Functional IDs supplied:  [1, 7]


Description of exchange functional: 

The Exchange function belongs to the family: LDA
Functional ID: 1
Functional Name: lda_x
Attributes:
    Name: Slater exchange
    Kind: 0
  Family: 1
Citations:
   P. A. M. Dirac, Math. Proc. Cambridge Philos. Soc. 26, 376 (1930)
   F. Bloch, Z. Phys. 57, 545 (1929)


Description of correlation functional: 

 The Correlation function belongs to the family: LDA
Functional ID: 7
Functional Name: lda_c_vwn
Attributes:
    Name: Vosko, Wilk & Nusair (VWN5)
    Kind: 1
  Family: 1
Citations:
   S. H. Vosko, L. Wilk, and M. Nusair, Can. J. Phys. 58, 1200 (1980)
------------------------------------------------------




Calculating XC term using GPU and algo 3
Not using LibXC for XC evaluations
